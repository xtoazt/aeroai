# Llama 3.1 405B Instruct FFT config
#
# Requirements:
#   - Set up your ALCF account (only available to Oumi core team)
#   - Set `user` to your ALCF username
#   - Log into WandB (`wandb login`) or disable `enable_wandb`
#   - Log into HF: `hf auth login`
#   - Request access to Llama 3.1: https://huggingface.co/meta-llama/Llama-3.1-405B-Instruct
#
# Usage:
#   oumi launch up -c configs/recipes/llama3_1/sft/405b_full/polaris_job.yaml --cluster prod.$ALCF_USER --user $ALCF_USER
#
# See Also:
#   - Documentation: https://oumi.ai/docs/en/latest/user_guides/launch/launch.html
#   - Config class: oumi.core.configs.JobConfig
#   - Config source: https://github.com/oumi-ai/oumi/blob/main/src/oumi/core/configs/job_config.py
#   - Other job configs: configs/**/*job.yaml

name: llama405b-fft
# NOTE: Replace with your username.
user: your_username

num_nodes: 20
resources:
  cloud: polaris

# Upload working directory to ~/oumi_launcher/{submission_time}
working_dir: .

setup: |
  #PBS -l place=scatter
  #PBS -l walltime=02:00:00
  #PBS -l filesystems=home:eagle
  #PBS -A community_ai
  #PBS -o /eagle/community_ai/jobs/logs/
  #PBS -e /eagle/community_ai/jobs/logs/

run: |
  set -e
  # Various setup for running on Polaris.
  source ${PBS_O_WORKDIR}/scripts/polaris/polaris_init.sh

  echo "Starting training with ${OUMI_NUM_NODES} node(s)..."

  set -x
  mpiexec --verbose \
      --np $OUMI_NUM_NODES -ppn ${NRANKS} -d ${NDEPTH} --cpu-bind ${CPU_BIND} \
      ./scripts/polaris/jobs/llama_tune.sh -m fft -d fsdp -s 405b

  echo -e "Finished training on ${OUMI_NUM_NODES} node(s):\n$(cat $PBS_NODEFILE)"
  echo "Polaris job is all done!"
